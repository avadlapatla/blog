{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6","title":"Welcome"},{"location":"#welcome","text":"","title":"Welcome"},{"location":"eks/cluster/","text":"Deploying EKS Cluster using eksctl \u00b6 Prerequisites \u00b6 Getting started with eksctl [ Instructions ] Setup \u00b6 eksctl supports creating and managing clusters leveraging YAML files. Using the following YAML configuration file, eksctl creates the cluster named west-example in the us-west-2 region. It then provisions EKS managed node group with SSM agent pre installed. apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: west-example region: us-west-2 managedNodeGroups: - name: managed-ng-1 minSize: 2 desiredCapacity: 2 maxSize: 4 instanceType: t3.medium preBootstrapCommands: - yum install -y amazon-ssm-agent - systemctl enable amazon-ssm-agent && systemctl start amazon-ssm-agent labels: role: worker tags: nodegroup-name: managed-ng-1 privateNetworking: true iam: attachPolicyARNs: - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly Copy the above configuration to a file named cluster.yaml and use the below command to provision the cluster and managed node groups eksctl create cluster -f cluster.yaml","title":"Setup EKS Cluster"},{"location":"eks/cluster/#deploying-eks-cluster-using-eksctl","text":"","title":"Deploying EKS Cluster using eksctl"},{"location":"eks/cluster/#prerequisites","text":"Getting started with eksctl [ Instructions ]","title":"Prerequisites"},{"location":"eks/cluster/#setup","text":"eksctl supports creating and managing clusters leveraging YAML files. Using the following YAML configuration file, eksctl creates the cluster named west-example in the us-west-2 region. It then provisions EKS managed node group with SSM agent pre installed. apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: west-example region: us-west-2 managedNodeGroups: - name: managed-ng-1 minSize: 2 desiredCapacity: 2 maxSize: 4 instanceType: t3.medium preBootstrapCommands: - yum install -y amazon-ssm-agent - systemctl enable amazon-ssm-agent && systemctl start amazon-ssm-agent labels: role: worker tags: nodegroup-name: managed-ng-1 privateNetworking: true iam: attachPolicyARNs: - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly Copy the above configuration to a file named cluster.yaml and use the below command to provision the cluster and managed node groups eksctl create cluster -f cluster.yaml","title":"Setup"},{"location":"eks/fargate_autoscaler/","text":"Deploying Cluster Autoscaler on EKS Fargate \u00b6 iam: withOIDC: true serviceAccounts: - metadata: name: cluster-autoscaler namespace: kube-system attachPolicy: # inline policy can be defined along with `attachPolicyARNs` Version: \"2012-10-17\" Statement: - Effect: Allow Action: - \"autoscaling:DescribeAutoScalingGroups\" - \"autoscaling:DescribeAutoScalingInstances\" - \"autoscaling:DescribeLaunchConfigurations\" - \"autoscaling:DescribeTags\" - \"ec2:DescribeLaunchTemplateVersions\" Resource: '*' - Effect: Allow Action: - \"autoscaling:SetDesiredCapacity\" - \"autoscaling:TerminateInstanceInAutoScalingGroup\" Resource: '*' Condition: StringEquals: autoscaling:ResourceTag/k8s.io/cluster-autoscaler/enabled : true autoscaling:ResourceTag/k8s.io/cluster-autoscaler/west-example: - owned - shared fargateProfiles: - name: fp-kube-system selectors: - namespace: kube-system labels: runtime: fargate Complete eksctl yaml configuration file can be downloaded from here cluster.yaml Fargate Profile \u00b6 The above eksctl configuration creates fargate profile named fp-kube-system. Pods that are run in the kube-system namespace and have the labels defined in the configuration will be scheduled on fargate. To create the fargate profile run the following command. eksctl create fargateprofile -f cluster.yaml Associate IAM OIDC Provider \u00b6 Run the following command to create IAM OIDC identity provider for EKS cluster eksctl utils associate-iam-oidc-provider -f cluster.yaml IAM Roles for Service Account \u00b6 eksctl makes it easy to create IAM roles for service account by define the policies in the configuration file. Run the following command to create cluster-autoscaler IAM role for service account, the policies attached to the service account will be leveraged by cluster autoscaler to auto discover and manage autoscaling groups. eksctl create iamserviceaccount -f cluster.yaml --override-existing-serviceaccounts Cluster Autoscaler Configurtion \u00b6 Download the cluster autoscaler example deployment file from here Replace the deployment object from the above file with the following content apiVersion: apps/v1 kind: Deployment metadata: name: cluster-autoscaler namespace: kube-system labels: app: cluster-autoscaler spec: replicas: 1 selector: matchLabels: app: cluster-autoscaler template: metadata: labels: app: cluster-autoscaler runtime: fargate annotations: prometheus.io/scrape: 'true' prometheus.io/port: '8085' spec: serviceAccountName: cluster-autoscaler containers: - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.17.3 name: cluster-autoscaler resources: limits: cpu: 100m memory: 300Mi requests: cpu: 100m memory: 300Mi command: - ./cluster-autoscaler - --v=4 - --stderrthreshold=info - --cloud-provider=aws - --skip-nodes-with-local-storage=false - --expander=least-waste - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/west-example volumeMounts: - name: ssl-certs mountPath: /etc/ssl/certs/ca-certificates.crt subPath: ca-certificates readOnly: true imagePullPolicy: \"Always\" env: - name: AWS_REGION value: us-west-2 volumes: - name: ssl-certs configMap: name: ssl-certs We are changing the way the cluster autoscaler is deployed on the EKS cluster. The deployment spec above leverages ssl-certs config map to mount ca-certificates. It also uses the latest container image matching the kubernetes version and cluster-autoscaler service account. Create ssl-certs configmap \u00b6 Cluster autoscaler requires ca-certificates, we will deploy ca-certificates as configmap and mount the configmap as volume in our deployment. The ca-certificates file can be downloded from here ssl-certs *Note ca-certificates file has been extracted from the pod running on Amazon Linux 2 (/etc/ssl/certs/ca-bundle.crt) Run the following command to create ssl-certs configmap kubectl create secret -n kube-system ssl-certs --from-file=ca-certificates=ca-certificates.crt Deploy Cluster Autoscaler \u00b6 Deploy cluster autoscaler using the following command kubectl apply -f cluster-autoscaler-autodiscover.yaml","title":"Cluster Autoscaler on Fargate"},{"location":"eks/fargate_autoscaler/#deploying-cluster-autoscaler-on-eks-fargate","text":"iam: withOIDC: true serviceAccounts: - metadata: name: cluster-autoscaler namespace: kube-system attachPolicy: # inline policy can be defined along with `attachPolicyARNs` Version: \"2012-10-17\" Statement: - Effect: Allow Action: - \"autoscaling:DescribeAutoScalingGroups\" - \"autoscaling:DescribeAutoScalingInstances\" - \"autoscaling:DescribeLaunchConfigurations\" - \"autoscaling:DescribeTags\" - \"ec2:DescribeLaunchTemplateVersions\" Resource: '*' - Effect: Allow Action: - \"autoscaling:SetDesiredCapacity\" - \"autoscaling:TerminateInstanceInAutoScalingGroup\" Resource: '*' Condition: StringEquals: autoscaling:ResourceTag/k8s.io/cluster-autoscaler/enabled : true autoscaling:ResourceTag/k8s.io/cluster-autoscaler/west-example: - owned - shared fargateProfiles: - name: fp-kube-system selectors: - namespace: kube-system labels: runtime: fargate Complete eksctl yaml configuration file can be downloaded from here cluster.yaml","title":"Deploying Cluster Autoscaler on EKS Fargate"},{"location":"eks/fargate_autoscaler/#fargate-profile","text":"The above eksctl configuration creates fargate profile named fp-kube-system. Pods that are run in the kube-system namespace and have the labels defined in the configuration will be scheduled on fargate. To create the fargate profile run the following command. eksctl create fargateprofile -f cluster.yaml","title":"Fargate Profile"},{"location":"eks/fargate_autoscaler/#associate-iam-oidc-provider","text":"Run the following command to create IAM OIDC identity provider for EKS cluster eksctl utils associate-iam-oidc-provider -f cluster.yaml","title":"Associate IAM OIDC Provider"},{"location":"eks/fargate_autoscaler/#iam-roles-for-service-account","text":"eksctl makes it easy to create IAM roles for service account by define the policies in the configuration file. Run the following command to create cluster-autoscaler IAM role for service account, the policies attached to the service account will be leveraged by cluster autoscaler to auto discover and manage autoscaling groups. eksctl create iamserviceaccount -f cluster.yaml --override-existing-serviceaccounts","title":"IAM Roles for Service Account"},{"location":"eks/fargate_autoscaler/#cluster-autoscaler-configurtion","text":"Download the cluster autoscaler example deployment file from here Replace the deployment object from the above file with the following content apiVersion: apps/v1 kind: Deployment metadata: name: cluster-autoscaler namespace: kube-system labels: app: cluster-autoscaler spec: replicas: 1 selector: matchLabels: app: cluster-autoscaler template: metadata: labels: app: cluster-autoscaler runtime: fargate annotations: prometheus.io/scrape: 'true' prometheus.io/port: '8085' spec: serviceAccountName: cluster-autoscaler containers: - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.17.3 name: cluster-autoscaler resources: limits: cpu: 100m memory: 300Mi requests: cpu: 100m memory: 300Mi command: - ./cluster-autoscaler - --v=4 - --stderrthreshold=info - --cloud-provider=aws - --skip-nodes-with-local-storage=false - --expander=least-waste - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/west-example volumeMounts: - name: ssl-certs mountPath: /etc/ssl/certs/ca-certificates.crt subPath: ca-certificates readOnly: true imagePullPolicy: \"Always\" env: - name: AWS_REGION value: us-west-2 volumes: - name: ssl-certs configMap: name: ssl-certs We are changing the way the cluster autoscaler is deployed on the EKS cluster. The deployment spec above leverages ssl-certs config map to mount ca-certificates. It also uses the latest container image matching the kubernetes version and cluster-autoscaler service account.","title":"Cluster Autoscaler Configurtion"},{"location":"eks/fargate_autoscaler/#create-ssl-certs-configmap","text":"Cluster autoscaler requires ca-certificates, we will deploy ca-certificates as configmap and mount the configmap as volume in our deployment. The ca-certificates file can be downloded from here ssl-certs *Note ca-certificates file has been extracted from the pod running on Amazon Linux 2 (/etc/ssl/certs/ca-bundle.crt) Run the following command to create ssl-certs configmap kubectl create secret -n kube-system ssl-certs --from-file=ca-certificates=ca-certificates.crt","title":"Create ssl-certs configmap"},{"location":"eks/fargate_autoscaler/#deploy-cluster-autoscaler","text":"Deploy cluster autoscaler using the following command kubectl apply -f cluster-autoscaler-autodiscover.yaml","title":"Deploy Cluster Autoscaler"},{"location":"eks/kubelet_customization/","text":"Kubelet Customization on Managed Node Groups using eksctl \u00b6 Amazon EKS managed node groups automates the provisioning and lifecycle management of Kubernetes nodes for you. Recently support for custom AMI and launch template has been added to the feature set Launch Announcement . eksctl has been updated to support this feature for managed node group. Kubelet args can be passed to bootstrap script via --kubelet-extra-args using overrideBootstrapCommand field. However, this command can only be set when a custom AMI is specified, so for this example we will just use EKS Optimized AMI. - name: managed-ng-2 ami: ami-05bc8cd159ecc4bcb minSize: 1 desiredCapacity: 1 maxSize: 4 instanceType: t3.medium preBootstrapCommands: - yum install -y amazon-ssm-agent - systemctl enable amazon-ssm-agent && systemctl start amazon-ssm-agent labels: role: worker tags: nodegroup-name: managed-ng-2 privateNetworking: true overrideBootstrapCommand: | /etc/eks/bootstrap.sh west-example --kubelet-extra-args '--serialize-image-pulls=true --cpu-cfs-quota=true' iam: attachPolicyARNs: - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly Complete eksctl yaml configuration file can be downloaded from here cluster.yaml","title":"Customizing kubelet"},{"location":"eks/kubelet_customization/#kubelet-customization-on-managed-node-groups-using-eksctl","text":"Amazon EKS managed node groups automates the provisioning and lifecycle management of Kubernetes nodes for you. Recently support for custom AMI and launch template has been added to the feature set Launch Announcement . eksctl has been updated to support this feature for managed node group. Kubelet args can be passed to bootstrap script via --kubelet-extra-args using overrideBootstrapCommand field. However, this command can only be set when a custom AMI is specified, so for this example we will just use EKS Optimized AMI. - name: managed-ng-2 ami: ami-05bc8cd159ecc4bcb minSize: 1 desiredCapacity: 1 maxSize: 4 instanceType: t3.medium preBootstrapCommands: - yum install -y amazon-ssm-agent - systemctl enable amazon-ssm-agent && systemctl start amazon-ssm-agent labels: role: worker tags: nodegroup-name: managed-ng-2 privateNetworking: true overrideBootstrapCommand: | /etc/eks/bootstrap.sh west-example --kubelet-extra-args '--serialize-image-pulls=true --cpu-cfs-quota=true' iam: attachPolicyARNs: - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly Complete eksctl yaml configuration file can be downloaded from here cluster.yaml","title":"Kubelet Customization on Managed Node Groups using eksctl"}]}